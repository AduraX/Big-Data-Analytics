{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis\n",
    "In this lab, you will create a classification model that performs sentiment analysis of tweets.\n",
    "### Import Spark SQL and Spark ML Libraries\n",
    "\n",
    "First, import the libraries you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer, StopWordsRemover}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Source Data\n",
    "Now load the tweets data into a DataFrame. This data consists of tweets that have been previously captured and classified as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|19        |5        |DL     |11433          |13303        |-3      |1       |\n",
      "|19        |5        |DL     |14869          |12478        |0       |-8      |\n",
      "|19        |5        |DL     |14057          |14869        |-4      |-15     |\n",
      "|19        |5        |DL     |15016          |11433        |28      |24      |\n",
      "|19        |5        |DL     |11193          |12892        |-6      |-11     |\n",
      "|19        |5        |DL     |10397          |15016        |-1      |-19     |\n",
      "|19        |5        |DL     |15016          |10397        |0       |-1      |\n",
      "|19        |5        |DL     |10397          |14869        |15      |24      |\n",
      "|19        |5        |DL     |10397          |10423        |33      |34      |\n",
      "|19        |5        |DL     |11278          |10397        |323     |322     |\n",
      "|19        |5        |DL     |14107          |13487        |-7      |-13     |\n",
      "|19        |5        |DL     |11433          |11298        |22      |41      |\n",
      "|19        |5        |DL     |11298          |11433        |40      |20      |\n",
      "|19        |5        |DL     |11433          |12892        |-2      |-7      |\n",
      "|19        |5        |DL     |10397          |12451        |71      |75      |\n",
      "|19        |5        |DL     |12451          |10397        |75      |57      |\n",
      "|19        |5        |DL     |12953          |10397        |-1      |10      |\n",
      "|19        |5        |DL     |11433          |12953        |-3      |-10     |\n",
      "|19        |5        |DL     |10397          |14771        |31      |38      |\n",
      "|19        |5        |DL     |13204          |10397        |8       |25      |\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val wkdir =\"file:///mnt/c/Users/Adura/Google Drive/Projects/Jupyter/SparkMs/data/\"\n",
    "val tweets_csv = spark.read.option(\"inferSchema\",\"true\").option(\"header\", \"true\").csv(wkdir + \"raw-flight-data.csv\")\n",
    "tweets_csv.show(truncate = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "The features for the classification model will be derived from the tweet text. The label is the sentiment (1 for positive, 0 for negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:32: error: value $ is not a member of StringContext\n",
       "       val data = tweets_csv.select($\"SentimentText\", $\"Sentiment\".cast(\"Int\").alias(\"label\"))\n",
       "                                    ^\n",
       "<console>:32: error: value $ is not a member of StringContext\n",
       "       val data = tweets_csv.select($\"SentimentText\", $\"Sentiment\".cast(\"Int\").alias(\"label\"))\n",
       "                                                      ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = tweets_csv.select($\"SentimentText\", $\"Sentiment\".cast(\"Int\").alias(\"label\"))\n",
    "data.show(truncate = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "In common with most classification modeling processes, you'll split the data into a set for training, and a set for testing the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:26: error: not found: value data\n",
       "       val splits = data.randomSplit(Array(0.7, 0.3))\n",
       "                    ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val splits = data.randomSplit(Array(0.7, 0.3))\n",
    "val train = splits(0)\n",
    "val test = splits(1).withColumnRenamed(\"label\", \"trueLabel\")\n",
    "val train_rows = train.count()\n",
    "val test_rows = test.count()\n",
    "println(\"Training Rows: \" + train_rows + \" Testing Rows: \" + test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pipeline\n",
    "The pipeline for the model consist of the following stages:\n",
    "- A Tokenizer to split the tweets into individual words.\n",
    "- A StopWordsRemover to remove common words such as \"a\" or \"the\" that have little predictive value.\n",
    "- A HashingTF class to generate numeric vectors from the text values.\n",
    "- A LogisticRegression algorithm to train a binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tokenizer = new Tokenizer().setInputCol(\"SentimentText\").setOutputCol(\"SentimentWords\")\n",
    "val swr = new StopWordsRemover().setInputCol(tokenizer.getOutputCol).setOutputCol(\"MeaningfulWords\")\n",
    "val hashTF = new HashingTF().setInputCol(swr.getOutputCol).setOutputCol(\"features\")\n",
    "val lr = new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10).setRegParam(0.01)\n",
    "val pipeline = new Pipeline().setStages(Array(tokenizer, swr, hashTF, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline as an Estimator\n",
    "The pipeline itself is an estimator, and so it has a **fit** method that you can call to run the pipeline on a specified DataFrame. In this case, you will run the pipeline on the training data to train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:36: error: not found: value train\n",
       "       val piplineModel = pipeline.fit(train)\n",
       "                                       ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val piplineModel = pipeline.fit(train)\n",
    "println(\"Pipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Pipeline Model\n",
    "The model produced by the pipeline is a transformer that will apply all of the stages in the pipeline to a specified DataFrame and apply the trained model to generate predictions. In this case, you will transform the **test** DataFrame using the pipeline to generate label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:26: error: not found: value piplineModel\n",
       "       val prediction = piplineModel.transform(test)\n",
       "                        ^\n",
       "<console>:26: error: not found: value test\n",
       "       val prediction = piplineModel.transform(test)\n",
       "                                               ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prediction = piplineModel.transform(test)\n",
    "val predicted = prediction.select(\"SentimentText\", \"features\", \"prediction\", \"trueLabel\")\n",
    "predicted.show(100, truncate = false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
